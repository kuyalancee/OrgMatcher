{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd07d269",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import sqlite3\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e1311720",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>short_name</th>\n",
       "      <th>summary</th>\n",
       "      <th>description</th>\n",
       "      <th>picture</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3D Printing Club</td>\n",
       "      <td>None</td>\n",
       "      <td>Learn about, design, use, and maintain additiv...</td>\n",
       "      <td>This is the 3D printing Club! We are a group o...</td>\n",
       "      <td>https://se-images.campuslabs.com/clink/images/...</td>\n",
       "      <td>https://unt.campuslabs.com/engage/organization...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               name short_name  \\\n",
       "0  3D Printing Club       None   \n",
       "\n",
       "                                             summary  \\\n",
       "0  Learn about, design, use, and maintain additiv...   \n",
       "\n",
       "                                         description  \\\n",
       "0  This is the 3D printing Club! We are a group o...   \n",
       "\n",
       "                                             picture  \\\n",
       "0  https://se-images.campuslabs.com/clink/images/...   \n",
       "\n",
       "                                                 url  \n",
       "0  https://unt.campuslabs.com/engage/organization...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conn = sqlite3.connect(\"../db_and_csvs/unt_clubs.db\")\n",
    "data = pd.read_sql(\"SELECT * FROM organizations ORDER BY name ASC LIMIT 1\", conn)\n",
    "data #test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8582f9c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0b3c52ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "db closed\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_sql_query(\"SELECT * FROM organizations\", conn)\n",
    "try:\n",
    "    conn.close()\n",
    "    print('db closed')\n",
    "except Exception as e:\n",
    "    print(f'db err: {e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a9a9e281",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>short_name</th>\n",
       "      <th>summary</th>\n",
       "      <th>description</th>\n",
       "      <th>picture</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3D Printing Club</td>\n",
       "      <td>None</td>\n",
       "      <td>Learn about, design, use, and maintain additiv...</td>\n",
       "      <td>This is the 3D printing Club! We are a group o...</td>\n",
       "      <td>https://se-images.campuslabs.com/clink/images/...</td>\n",
       "      <td>https://unt.campuslabs.com/engage/organization...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               name short_name  \\\n",
       "0  3D Printing Club       None   \n",
       "\n",
       "                                             summary  \\\n",
       "0  Learn about, design, use, and maintain additiv...   \n",
       "\n",
       "                                         description  \\\n",
       "0  This is the 3D printing Club! We are a group o...   \n",
       "\n",
       "                                             picture  \\\n",
       "0  https://se-images.campuslabs.com/clink/images/...   \n",
       "\n",
       "                                                 url  \n",
       "0  https://unt.campuslabs.com/engage/organization...  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8057a58d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define lemmatizer\n",
    "lemmatize = WordNetLemmatizer()\n",
    "\n",
    "def lemmatize_text(text):\n",
    "    text = text.lower().translate(str.maketrans('','', 'string.punctuation'))\n",
    "    terms = text.split()\n",
    "    return \" \".join([lemmatize.lemmatize(word) for word in terms])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e4ad8e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define 'document' as described on the paper\n",
    "# 2* weight on short_name\n",
    "data.fillna('')\n",
    "data['document'] = (\n",
    "    data['name'] + \" \" + \n",
    "    data['short_name'].astype(str) + \" \" + data['short_name'].astype(str) + \" \" +\n",
    "    data['summary'] + \" \" + \n",
    "    data['description']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "4e6a58c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "db closed\n",
      "top 5 matches:\n",
      "                                        name short_name\n",
      "1                  Asian Student Association        ASA\n",
      "2  Society of Asian Scientists and Engineers   UNT SASE\n",
      "3              SALT South Asian InterVarsity  SALT SAIV\n",
      "4                North Texas Pickleball Club       NTPC\n",
      "5         Delta Epsilon Psi Fraternity, Inc.      DEPsi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jtras\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\feature_extraction\\text.py:411: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ha', 'wa'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction import text\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import nltk\n",
    "import sqlite3\n",
    "import string\n",
    "\n",
    "def access_and_load_db():\n",
    "    conn = sqlite3.connect(\"db_and_csvs/unt_clubs.db\")\n",
    "    data = pd.read_sql_query(\"SELECT * FROM organizations\", conn)\n",
    "    try:\n",
    "        conn.close()\n",
    "        print('db closed')\n",
    "    except Exception as e:\n",
    "        print(f'db err: {e}')\n",
    "    # define 'document' as described on the paper\n",
    "    # 2* weight on short_name\n",
    "    data = data.fillna('')\n",
    "    data['document'] = (\n",
    "        data['name'] + \" \" + \n",
    "        data['short_name'].astype(str) + \" \" + data['short_name'].astype(str) + \" \" +\n",
    "        data['summary'] + \" \" + \n",
    "        data['description']\n",
    "    )\n",
    "    return data\n",
    "\n",
    "\n",
    "# define lemmatizer\n",
    "lemmatize = WordNetLemmatizer()\n",
    "def lemmatize_text(text):\n",
    "    text = text.lower().translate(str.maketrans('','', string.punctuation))\n",
    "    terms = text.split()\n",
    "    return \" \".join([lemmatize.lemmatize(word) for word in terms])\n",
    "\n",
    "\n",
    "def get_recommendations(query, data, tfidf_vectorizer, tfidf_matrix):\n",
    "    query_vectorized = tfidf_vectorizer.transform([query])\n",
    "    cosine_sim = cosine_similarity(query_vectorized, tfidf_matrix)\n",
    "    top_five = np.argsort(cosine_sim[0])[-5:][::-1]\n",
    "    return data.iloc[top_five]\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    data = access_and_load_db()\n",
    "\n",
    "    stop_words = list(text.ENGLISH_STOP_WORDS)\n",
    "    lemmatized_stop_words = [lemmatize.lemmatize(word) for word in stop_words]\n",
    "\n",
    "    #https://www.geeksforgeeks.org/machine-learning/music-recommendation-system-using-machine-learning/\n",
    "    #https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html\n",
    "    #ref\n",
    "    tfidf = TfidfVectorizer(\n",
    "        preprocessor=lemmatize_text,\n",
    "        stop_words='english',\n",
    "        token_pattern=r\"\\b\\w\\w+\\b\"\n",
    "    )\n",
    "    tfidf_matrix = tfidf.fit_transform(data['document'])\n",
    "\n",
    "    usr_input = \"i am asian and looking for new friends\"\n",
    "    res = get_recommendations(usr_input, data, tfidf, tfidf_matrix)\n",
    "\n",
    "    print(f'top 5 matches:')\n",
    "    res_display = res[['name', 'short_name']].reset_index(drop=True)\n",
    "    res_display.index = res_display.index + 1\n",
    "    print(res_display)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08cbfaf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error: unable to open database file\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction import text\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import nltk\n",
    "import sqlite3\n",
    "import string\n",
    "\n",
    "SYNONYM_MAP = {\n",
    "    \"acct\": \"accounting\",\n",
    "    \"aero\": \"aerospace engineering\",\n",
    "    \"african\": \"african\",\n",
    "    \"ai\": \"artificial intelligence\",\n",
    "    \"alliance\": \"alliance\",\n",
    "    \"arab\": \"arab\",\n",
    "    \"arch\": \"architecture\",\n",
    "    \"art\": \"art\",\n",
    "    \"asian\": \"asian\",\n",
    "    \"assoc\": \"association\",\n",
    "    \"athletic\": \"athletics\",\n",
    "    \"award\": \"award\",\n",
    "    \"badminton\": \"badminton\",\n",
    "    \"basketball\": \"basketball\",\n",
    "    \"bio\": \"biology\",\n",
    "    \"bioeng\": \"biomedical engineering\",\n",
    "    \"biz\": \"business\",\n",
    "    \"brazilian\": \"brazilian\",\n",
    "    \"campus\": \"campus ministry\",\n",
    "    \"charity\": \"charity\",\n",
    "    \"chem\": \"chemistry\",\n",
    "    \"chinese\": \"chinese\",\n",
    "    \"christian\": \"christian\",\n",
    "    \"civil\": \"civil engineering\",\n",
    "    \"club\": \"club\",\n",
    "    \"club sports\": \"club sports\",\n",
    "    \"cs\": \"computer science\",\n",
    "    \"cse\": \"computer science engineering\",\n",
    "    \"cultural\": \"cultural\",\n",
    "    \"dance\": \"dance\",\n",
    "    \"db\": \"database\",\n",
    "    \"dent\": \"dental\",\n",
    "    \"design\": \"design\",\n",
    "    \"devops\": \"devops engineering\",\n",
    "    \"diversity\": \"diversity\",\n",
    "    \"econ\": \"economics\",\n",
    "    \"elec\": \"electrical engineering\",\n",
    "    \"eng\": \"english\",\n",
    "    \"entrepreneurship\": \"entrepreneurship\",\n",
    "    \"faith\": \"faith\",\n",
    "    \"fellowship\": \"fellowship\",\n",
    "    \"fin\": \"finance\",\n",
    "    \"football\": \"football\",\n",
    "    \"frat\": \"fraternity\",\n",
    "    \"fullstack\": \"full stack development\",\n",
    "    \"golf\": \"golf\",\n",
    "    \"gov\": \"government\",\n",
    "    \"graduate\": \"graduate\",\n",
    "    \"greek\": \"greek life\",\n",
    "    \"group\": \"group\",\n",
    "    \"hist\": \"history\",\n",
    "    \"honors\": \"honors\",\n",
    "    \"hr\": \"human resources\",\n",
    "    \"inclusion\": \"inclusion\",\n",
    "    \"indian\": \"indian\",\n",
    "    \"innovation\": \"innovation\",\n",
    "    \"international\": \"international\",\n",
    "    \"intl\": \"international\",\n",
    "    \"intramural\": \"intramural\",\n",
    "    \"it\": \"information technology\",\n",
    "    \"japanese\": \"japanese\",\n",
    "    \"korean\": \"korean\",\n",
    "    \"lacrosse\": \"lacrosse\",\n",
    "    \"latin\": \"latin american\",\n",
    "    \"law\": \"law\",\n",
    "    \"lgbtq\": \"lgbtq\",\n",
    "    \"lgbtqia\": \"lgbtq\",\n",
    "    \"lit\": \"literature\",\n",
    "    \"mech\": \"mechanical engineering\",\n",
    "    \"med\": \"medicine\",\n",
    "    \"mexican\": \"mexican\",\n",
    "    \"mgmt\": \"management\",\n",
    "    \"ministry\": \"ministry\",\n",
    "    \"mkt\": \"marketing\",\n",
    "    \"ml\": \"machine learning\",\n",
    "    \"music\": \"music\",\n",
    "    \"muslim\": \"muslim\",\n",
    "    \"neuro\": \"neuroscience\",\n",
    "    \"nsls\": \"national society of leadership and success\",\n",
    "    \"nursing\": \"nursing\",\n",
    "    \"org\": \"organization\",\n",
    "    \"outreach\": \"community outreach\",\n",
    "    \"pharm\": \"pharmacy\",\n",
    "    \"philanthropy\": \"philanthropy\",\n",
    "    \"phys\": \"physics\",\n",
    "    \"pickleball\": \"pickleball\",\n",
    "    \"pol\": \"political science\",\n",
    "    \"pre-med\": \"pre-medicine\",\n",
    "    \"pre-vet\": \"pre-veterinary medicine\",\n",
    "    \"professional\": \"professional\",\n",
    "    \"psych\": \"psychology\",\n",
    "    \"pt\": \"physical therapy\",\n",
    "    \"pta\": \"physical therapy assistant\",\n",
    "    \"rotc\": \"reserve officers training corps\",\n",
    "    \"rugby\": \"rugby\",\n",
    "    \"sales\": \"sales\",\n",
    "    \"sci\": \"science\",\n",
    "    \"service\": \"community service\",\n",
    "    \"soc\": \"society\",\n",
    "    \"soccer\": \"soccer\",\n",
    "    \"social\": \"social\",\n",
    "    \"sorority\": \"sorority\",\n",
    "    \"sports\": \"sports\",\n",
    "    \"sql\": \"database\",\n",
    "    \"student\": \"student\",\n",
    "    \"swe\": \"software engineering\",\n",
    "    \"swimming\": \"swimming\",\n",
    "    \"tennis\": \"tennis\",\n",
    "    \"theater\": \"theatre\",\n",
    "    \"ttu\": \"texas tech university\",\n",
    "    \"unt\": \"university of north texas\",\n",
    "    \"ut\": \"university of texas\",\n",
    "    \"vet\": \"veterinary\",\n",
    "    \"volleyball\": \"volleyball\",\n",
    "    \"volunteer\": \"volunteering\",\n",
    "    \"web\": \"web development\",\n",
    "}\n",
    "\n",
    "def access_and_load_db():\n",
    "    conn = sqlite3.connect(\"db_and_csvs/unt_clubs.db\")\n",
    "    data = pd.read_sql_query(\"SELECT * FROM organizations\", conn)\n",
    "    try:\n",
    "        conn.close()\n",
    "        print('db closed')\n",
    "    except Exception as e:\n",
    "        print(f'db err: {e}')\n",
    "    # define 'document' as described on the paper\n",
    "    # increase weight on short_name\n",
    "    data = data.fillna('')\n",
    "    data['document'] = (\n",
    "        data['name'] + \" \" + \n",
    "        data['short_name'].astype(str) + \" \" + data['short_name'].astype(str) + \" \" +\n",
    "        data['summary'] + \" \" + \n",
    "        data['description']\n",
    "    )\n",
    "    #print(type(data))\n",
    "    return data\n",
    "\n",
    "\n",
    "# define lemmatizer\n",
    "lemmatize = WordNetLemmatizer()\n",
    "def lemmatize_text(text):\n",
    "    text = text.lower().translate(str.maketrans('','', string.punctuation))\n",
    "    terms = text.split()\n",
    "    new_words = [SYNONYM_MAP.get(word, word) for word in terms]\n",
    "\n",
    "    return \" \".join([lemmatize.lemmatize(word) for word in new_words])\n",
    "\n",
    "\n",
    "def get_recommendations(query, data, tfidf_vectorizer, tfidf_matrix):\n",
    "    query_vectorized = tfidf_vectorizer.transform([query])\n",
    "    cosine_sim = cosine_similarity(query_vectorized, tfidf_matrix)\n",
    "    top_five = np.argsort(cosine_sim[0])[-5:][::-1]\n",
    "    return data.iloc[top_five]\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        data = access_and_load_db()\n",
    "\n",
    "        stop_words = list(text.ENGLISH_STOP_WORDS)\n",
    "        lemmatized_stop_words = [lemmatize.lemmatize(word) for word in stop_words]\n",
    "\n",
    "        tfidf = TfidfVectorizer(\n",
    "            preprocessor=lemmatize_text,\n",
    "            stop_words=lemmatized_stop_words,\n",
    "            token_pattern=r\"\\b\\w\\w+\\b\"\n",
    "        )\n",
    "        tfidf_matrix = tfidf.fit_transform(data['document'])\n",
    "\n",
    "        usr_input = input(\"Enter what you're looking for in an organization: \")\n",
    "        res = get_recommendations(usr_input, data, tfidf, tfidf_matrix)\n",
    "\n",
    "        print(f'top 5 matches for {usr_input}:')\n",
    "        res_display = res[['name', 'short_name']].reset_index(drop=True)\n",
    "        res_display.index = res_display.index + 1\n",
    "        print(res_display)\n",
    "    except Exception as e:\n",
    "        print(f'error: {e}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
