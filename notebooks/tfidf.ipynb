{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fd07d269",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import sqlite3\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e1311720",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>short_name</th>\n",
       "      <th>summary</th>\n",
       "      <th>description</th>\n",
       "      <th>picture</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3D Printing Club</td>\n",
       "      <td>None</td>\n",
       "      <td>Learn about, design, use, and maintain additiv...</td>\n",
       "      <td>This is the 3D printing Club! We are a group o...</td>\n",
       "      <td>https://se-images.campuslabs.com/clink/images/...</td>\n",
       "      <td>https://unt.campuslabs.com/engage/organization...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               name short_name  \\\n",
       "0  3D Printing Club       None   \n",
       "\n",
       "                                             summary  \\\n",
       "0  Learn about, design, use, and maintain additiv...   \n",
       "\n",
       "                                         description  \\\n",
       "0  This is the 3D printing Club! We are a group o...   \n",
       "\n",
       "                                             picture  \\\n",
       "0  https://se-images.campuslabs.com/clink/images/...   \n",
       "\n",
       "                                                 url  \n",
       "0  https://unt.campuslabs.com/engage/organization...  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conn = sqlite3.connect(\"db_and_csvs/unt_clubs.db\")\n",
    "data = pd.read_sql(\"SELECT * FROM organizations ORDER BY name ASC LIMIT 1\", conn)\n",
    "data #test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0b3c52ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "db closed\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_sql_query(\"SELECT * FROM organizations\", conn)\n",
    "try:\n",
    "    conn.close()\n",
    "    print('db closed')\n",
    "except Exception as e:\n",
    "    print(f'db err: {e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a9a9e281",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>short_name</th>\n",
       "      <th>summary</th>\n",
       "      <th>description</th>\n",
       "      <th>picture</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3D Printing Club</td>\n",
       "      <td>None</td>\n",
       "      <td>Learn about, design, use, and maintain additiv...</td>\n",
       "      <td>This is the 3D printing Club! We are a group o...</td>\n",
       "      <td>https://se-images.campuslabs.com/clink/images/...</td>\n",
       "      <td>https://unt.campuslabs.com/engage/organization...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               name short_name  \\\n",
       "0  3D Printing Club       None   \n",
       "\n",
       "                                             summary  \\\n",
       "0  Learn about, design, use, and maintain additiv...   \n",
       "\n",
       "                                         description  \\\n",
       "0  This is the 3D printing Club! We are a group o...   \n",
       "\n",
       "                                             picture  \\\n",
       "0  https://se-images.campuslabs.com/clink/images/...   \n",
       "\n",
       "                                                 url  \n",
       "0  https://unt.campuslabs.com/engage/organization...  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8057a58d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define lemmatizer\n",
    "lemmatize = WordNetLemmatizer()\n",
    "\n",
    "def lemmatize_text(text):\n",
    "    text = text.lower().translate(str.maketrans('','', 'string.punctuation'))\n",
    "    terms = text.split()\n",
    "    return \" \".join([lemmatize.lemmatize(word) for word in terms])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e4ad8e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define 'document' as described on the paper\n",
    "# 2* weight on short_name\n",
    "data.fillna('')\n",
    "data['document'] = (\n",
    "    data['name'] + \" \" + \n",
    "    data['short_name'].astype(str) + \" \" + data['short_name'].astype(str) + \" \" +\n",
    "    data['summary'] + \" \" + \n",
    "    data['description']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "4e6a58c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "db closed\n",
      "top 5 matches:\n",
      "                                        name short_name\n",
      "1                  Asian Student Association        ASA\n",
      "2  Society of Asian Scientists and Engineers   UNT SASE\n",
      "3              SALT South Asian InterVarsity  SALT SAIV\n",
      "4                North Texas Pickleball Club       NTPC\n",
      "5         Delta Epsilon Psi Fraternity, Inc.      DEPsi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jtras\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\feature_extraction\\text.py:411: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ha', 'wa'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction import text\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import nltk\n",
    "import sqlite3\n",
    "import string\n",
    "\n",
    "def access_and_load_db():\n",
    "    conn = sqlite3.connect(\"db_and_csvs/unt_clubs.db\")\n",
    "    data = pd.read_sql_query(\"SELECT * FROM organizations\", conn)\n",
    "    try:\n",
    "        conn.close()\n",
    "        print('db closed')\n",
    "    except Exception as e:\n",
    "        print(f'db err: {e}')\n",
    "    # define 'document' as described on the paper\n",
    "    # 2* weight on short_name\n",
    "    data = data.fillna('')\n",
    "    data['document'] = (\n",
    "        data['name'] + \" \" + \n",
    "        data['short_name'].astype(str) + \" \" + data['short_name'].astype(str) + \" \" +\n",
    "        data['summary'] + \" \" + \n",
    "        data['description']\n",
    "    )\n",
    "    return data\n",
    "\n",
    "\n",
    "# define lemmatizer\n",
    "lemmatize = WordNetLemmatizer()\n",
    "def lemmatize_text(text):\n",
    "    text = text.lower().translate(str.maketrans('','', string.punctuation))\n",
    "    terms = text.split()\n",
    "    return \" \".join([lemmatize.lemmatize(word) for word in terms])\n",
    "\n",
    "\n",
    "def get_recommendations(query, data, tfidf_vectorizer, tfidf_matrix):\n",
    "    query_vectorized = tfidf_vectorizer.transform([query])\n",
    "    cosine_sim = cosine_similarity(query_vectorized, tfidf_matrix)\n",
    "    top_five = np.argsort(cosine_sim[0])[-5:][::-1]\n",
    "    return data.iloc[top_five]\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    data = access_and_load_db()\n",
    "\n",
    "    stop_words = list(text.ENGLISH_STOP_WORDS)\n",
    "    lemmatized_stop_words = [lemmatize.lemmatize(word) for word in stop_words]\n",
    "\n",
    "    #https://www.geeksforgeeks.org/machine-learning/music-recommendation-system-using-machine-learning/\n",
    "    #https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html\n",
    "    #ref\n",
    "    tfidf = TfidfVectorizer(\n",
    "        preprocessor=lemmatize_text,\n",
    "        stop_words='english',\n",
    "        token_pattern=r\"\\b\\w\\w+\\b\"\n",
    "    )\n",
    "    tfidf_matrix = tfidf.fit_transform(data['document'])\n",
    "\n",
    "    usr_input = \"i am asian and looking for new friends\"\n",
    "    res = get_recommendations(usr_input, data, tfidf, tfidf_matrix)\n",
    "\n",
    "    print(f'top 5 matches:')\n",
    "    res_display = res[['name', 'short_name']].reset_index(drop=True)\n",
    "    res_display.index = res_display.index + 1\n",
    "    print(res_display)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
